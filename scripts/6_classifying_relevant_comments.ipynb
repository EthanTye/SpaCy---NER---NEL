{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime as dt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting GPU usage\n",
    "spacy.prefer_gpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Loading Model trained with the NEL\n",
    "nlp = spacy.load('../model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555745280\n"
     ]
    },
    {
     "data": {
      "text/plain": "8589606912"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.memory_reserved(0))\n",
    "torch.cuda.get_device_properties(0).total_memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/comments_clean.pk1')\n",
    "# the full file isnt available on github a smaller file is provided"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace = True)\n",
    "df.dropna(axis = 0, subset = 'comment', inplace = True)\n",
    "df.drop_duplicates(subset = ['comment'], keep = 'first', inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1490073 entries, 0 to 1882366\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   comment         1490073 non-null  object \n",
      " 1   user            1427993 non-null  object \n",
      " 2   date_time       1490069 non-null  float64\n",
      " 3   sub_title       1490069 non-null  object \n",
      " 4   clean_comments  1490073 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 68.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#creating mirror df without nulls in the title\n",
    "df2 = df.dropna(subset = 'sub_title', axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "unique_titles = [title  for title in df2.sub_title.unique()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df= df[df.comment != '[deleted]']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1490072 entries, 0 to 1882366\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   comment         1490072 non-null  object \n",
      " 1   user            1427993 non-null  object \n",
      " 2   date_time       1490068 non-null  float64\n",
      " 3   sub_title       1490068 non-null  object \n",
      " 4   clean_comments  1490072 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 68.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df['comment_len'] = [len(comment) for comment in df.comment]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df['comment_len'] = [len(comment.split()) for comment in df.comment]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df = df[df.user != 'sneakpeek_bot']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   comment  \\\n1014060  Yeah. It was about 4 years ago. I stepped on 7...   \n1085916  I’d like to talk about bullying too. Back in 2...   \n1394723  >  Goh Chok Tong story: Lessons for 4G leaders...   \n709896   Summary of points by Sylvia in the linked vide...   \n834395   They scrubbed their  but I managed to recover ...   \n...                                                    ...   \n1468221                                                      \n1658411                                                      \n39933                                                        \n160154                                                       \n610157                                                       \n\n                       user     date_time  \\\n1014060        Public_Halir  1.628423e+09   \n1085916    Tsuikyit_The_VIP  1.626886e+09   \n1394723           Varantain  1.620521e+09   \n709896           Human-Feed  1.635086e+09   \n834395              Eurito1  1.632624e+09   \n...                     ...           ...   \n1468221     WhimsyQuodlibet  1.618670e+09   \n1658411  dontdownvotemebruh  1.610699e+09   \n39933        random_avocado  1.646030e+09   \n160154          dawnfire999  1.642508e+09   \n610157                 rfnv  1.637577e+09   \n\n                                                 sub_title  \\\n1014060  For those who accidentally stepped on 7th Mont...   \n1085916  Personal story regarding mental health and bul...   \n1394723        Goh Chok Tong story: Lessons for 4G leaders   \n709896   Trailer: Xiaxue's Exclusive interview with Sylvia   \n834395   Statement from BooksActually staff (without Ke...   \n...                                                    ...   \n1468221  /r/singapore random discussion and small quest...   \n1658411  British man, Singaporean fiancee charged after...   \n39933    /r/singapore random discussion and small quest...   \n160154   How is the criminal justice system (accused ri...   \n610157   /r/singapore random discussion and small quest...   \n\n                                            clean_comments  comment_len  \n1014060  Yeah. It was about 4 years ago. I stepped on 7...         1869  \n1085916  I’d like to talk about bullying too. Back in 2...         1866  \n1394723  >  Goh Chok Tong story: Lessons for 4G leaders...         1842  \n709896   Summary of points by Sylvia in the linked vide...         1827  \n834395   They scrubbed their  but I managed to recover ...         1800  \n...                                                    ...          ...  \n1468221                                                               0  \n1658411                                                               0  \n39933                                                                 0  \n160154                                                                0  \n610157                                                                0  \n\n[1483093 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>user</th>\n      <th>date_time</th>\n      <th>sub_title</th>\n      <th>clean_comments</th>\n      <th>comment_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1014060</th>\n      <td>Yeah. It was about 4 years ago. I stepped on 7...</td>\n      <td>Public_Halir</td>\n      <td>1.628423e+09</td>\n      <td>For those who accidentally stepped on 7th Mont...</td>\n      <td>Yeah. It was about 4 years ago. I stepped on 7...</td>\n      <td>1869</td>\n    </tr>\n    <tr>\n      <th>1085916</th>\n      <td>I’d like to talk about bullying too. Back in 2...</td>\n      <td>Tsuikyit_The_VIP</td>\n      <td>1.626886e+09</td>\n      <td>Personal story regarding mental health and bul...</td>\n      <td>I’d like to talk about bullying too. Back in 2...</td>\n      <td>1866</td>\n    </tr>\n    <tr>\n      <th>1394723</th>\n      <td>&gt;  Goh Chok Tong story: Lessons for 4G leaders...</td>\n      <td>Varantain</td>\n      <td>1.620521e+09</td>\n      <td>Goh Chok Tong story: Lessons for 4G leaders</td>\n      <td>&gt;  Goh Chok Tong story: Lessons for 4G leaders...</td>\n      <td>1842</td>\n    </tr>\n    <tr>\n      <th>709896</th>\n      <td>Summary of points by Sylvia in the linked vide...</td>\n      <td>Human-Feed</td>\n      <td>1.635086e+09</td>\n      <td>Trailer: Xiaxue's Exclusive interview with Sylvia</td>\n      <td>Summary of points by Sylvia in the linked vide...</td>\n      <td>1827</td>\n    </tr>\n    <tr>\n      <th>834395</th>\n      <td>They scrubbed their  but I managed to recover ...</td>\n      <td>Eurito1</td>\n      <td>1.632624e+09</td>\n      <td>Statement from BooksActually staff (without Ke...</td>\n      <td>They scrubbed their  but I managed to recover ...</td>\n      <td>1800</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1468221</th>\n      <td></td>\n      <td>WhimsyQuodlibet</td>\n      <td>1.618670e+09</td>\n      <td>/r/singapore random discussion and small quest...</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1658411</th>\n      <td></td>\n      <td>dontdownvotemebruh</td>\n      <td>1.610699e+09</td>\n      <td>British man, Singaporean fiancee charged after...</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39933</th>\n      <td></td>\n      <td>random_avocado</td>\n      <td>1.646030e+09</td>\n      <td>/r/singapore random discussion and small quest...</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>160154</th>\n      <td></td>\n      <td>dawnfire999</td>\n      <td>1.642508e+09</td>\n      <td>How is the criminal justice system (accused ri...</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>610157</th>\n      <td></td>\n      <td>rfnv</td>\n      <td>1.637577e+09</td>\n      <td>/r/singapore random discussion and small quest...</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1483093 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'comment_len', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26277/26277 [06:36<00:00, 66.30it/s]\n"
     ]
    }
   ],
   "source": [
    "title_ents = []\n",
    "title_list = []\n",
    "title_dict = {}\n",
    "count = 0\n",
    "for doc in nlp.pipe(tqdm(unique_titles)):\n",
    "    doc_ents = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.kb_id_ != 'NIL':\n",
    "            ent_details = ent.kb_id_\n",
    "            doc_ents.append(ent_details)\n",
    "    title_ents.append(doc_ents)\n",
    "    title_list.append(doc.text)\n",
    "\n",
    "    title_dict[f'{count}'] = {'comment': doc.text}\n",
    "    relevant_sections = {}\n",
    "    for ents in doc.ents:\n",
    "        relevant_sections[f'{ents.kb_id_}'] = []\n",
    "        for token in ents:\n",
    "            if token.ent_iob == 3:\n",
    "                clause = {}\n",
    "                current_token = token\n",
    "                subject_count = 1\n",
    "                while current_token.dep_ != \"ROOT\" and subject_count <= 1:\n",
    "                    if current_token.dep_ ==  'nsubj' or current_token.dep_== 'iobj' or current_token.dep_== 'dobj' or current_token.dep_ == 'pobj':\n",
    "                        subject_count += 1\n",
    "                        current_token = current_token.head\n",
    "                    else:\n",
    "                        current_token = current_token.head\n",
    "        section = [t for t in current_token.subtree]\n",
    "        relevant_sections[f'{ents.kb_id_}'].append(section)\n",
    "        title_dict[f'{count}']['entities'] = relevant_sections\n",
    "    count +=1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "title_df= pd.DataFrame({'title': title_list, 'title_ents': title_ents})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "title_df = title_df[title_df.title_ents.map(lambda x: len(x))>0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "titles_with_ents = [titles for titles in title_df.title]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "comment_ents = []\n",
    "\n",
    "comment = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\nfor doc in nlp.pipe(tqdm(df.clean_comments)):\\n    doc_ents = []\\n    for ent in doc.ents:\\n        if ent.kb_id_ != 'NIL':\\n            ent_details = ent.kb_id_\\n            doc_ents.append(ent_details)\\n            comment.append(doc.text)\\n    comment_ents.append(doc_ents)\\n    comment.append(doc.text)\\n\\n\""
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "for doc in nlp.pipe(tqdm(df.clean_comments)):\n",
    "    doc_ents = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.kb_id_ != 'NIL':\n",
    "            ent_details = ent.kb_id_\n",
    "            doc_ents.append(ent_details)\n",
    "            comment.append(doc.text)\n",
    "    comment_ents.append(doc_ents)\n",
    "    comment.append(doc.text)\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 81169/1483093 [10:52:24<187:48:04,  2.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4072/1483093 [01:43<39:33:34, 10.39it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\language.py\u001B[0m in \u001B[0;36mpipe\u001B[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001B[0m\n\u001B[0;32m   1573\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mpipe\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpipes\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1574\u001B[0m                 \u001B[0mdocs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpipe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1575\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdocs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1576\u001B[0m             \u001B[1;32myield\u001B[0m \u001B[0mdoc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1577\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36m_pipe\u001B[1;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[0;32m   1596\u001B[0m ) -> Iterator[\"Doc\"]:\n\u001B[0;32m   1597\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mproc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"pipe\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1598\u001B[1;33m         \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mproc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1599\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1600\u001B[0m         \u001B[1;31m# We added some args for pipe that __call__ doesn't expect.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001B[0m in \u001B[0;36mpipe\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36mminibatch\u001B[1;34m(items, size)\u001B[0m\n\u001B[0;32m   1545\u001B[0m     \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1546\u001B[0m         \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1547\u001B[1;33m         \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitertools\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mislice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1548\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1549\u001B[0m             \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36m_pipe\u001B[1;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[0;32m   1596\u001B[0m ) -> Iterator[\"Doc\"]:\n\u001B[0;32m   1597\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mproc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"pipe\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1598\u001B[1;33m         \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mproc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1599\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1600\u001B[0m         \u001B[1;31m# We added some args for pipe that __call__ doesn't expect.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001B[0m in \u001B[0;36mpipe\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36mminibatch\u001B[1;34m(items, size)\u001B[0m\n\u001B[0;32m   1545\u001B[0m     \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1546\u001B[0m         \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1547\u001B[1;33m         \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitertools\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mislice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1548\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1549\u001B[0m             \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36m_pipe\u001B[1;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[0;32m   1596\u001B[0m ) -> Iterator[\"Doc\"]:\n\u001B[0;32m   1597\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mproc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"pipe\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1598\u001B[1;33m         \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mproc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1599\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1600\u001B[0m         \u001B[1;31m# We added some args for pipe that __call__ doesn't expect.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\pipeline\\pipe.pyx\u001B[0m in \u001B[0;36mpipe\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36m_pipe\u001B[1;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[0;32m   1596\u001B[0m ) -> Iterator[\"Doc\"]:\n\u001B[0;32m   1597\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mproc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"pipe\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1598\u001B[1;33m         \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mproc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1599\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1600\u001B[0m         \u001B[1;31m# We added some args for pipe that __call__ doesn't expect.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001B[0m in \u001B[0;36mpipe\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36mminibatch\u001B[1;34m(items, size)\u001B[0m\n\u001B[0;32m   1545\u001B[0m     \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1546\u001B[0m         \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1547\u001B[1;33m         \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitertools\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mislice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1548\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1549\u001B[0m             \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36m_pipe\u001B[1;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[0;32m   1596\u001B[0m ) -> Iterator[\"Doc\"]:\n\u001B[0;32m   1597\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mproc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"pipe\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1598\u001B[1;33m         \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mproc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1599\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1600\u001B[0m         \u001B[1;31m# We added some args for pipe that __call__ doesn't expect.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001B[0m in \u001B[0;36mpipe\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36mminibatch\u001B[1;34m(items, size)\u001B[0m\n\u001B[0;32m   1545\u001B[0m     \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1546\u001B[0m         \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1547\u001B[1;33m         \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitertools\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mislice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1548\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1549\u001B[0m             \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\util.py\u001B[0m in \u001B[0;36m_pipe\u001B[1;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[0;32m   1596\u001B[0m ) -> Iterator[\"Doc\"]:\n\u001B[0;32m   1597\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mproc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"pipe\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1598\u001B[1;33m         \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mproc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1599\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1600\u001B[0m         \u001B[1;31m# We added some args for pipe that __call__ doesn't expect.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy_transformers\\pipeline_component.py\u001B[0m in \u001B[0;36mpipe\u001B[1;34m(self, stream, batch_size)\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mindices\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mbatch_by_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mouter_batch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcfg\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"max_batch_items\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m                 \u001B[0msubbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mouter_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mindices\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 212\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_annotations\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    213\u001B[0m             \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mouter_batch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy_transformers\\pipeline_component.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, docs)\u001B[0m\n\u001B[0;32m    226\u001B[0m             \u001B[0mactivations\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFullTransformerBatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    227\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 228\u001B[1;33m             \u001B[0mactivations\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    229\u001B[0m         \u001B[0mbatch_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTransformerListener\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_batch_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    230\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mlistener\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlisteners\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\thinc\\model.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[0monly\u001B[0m \u001B[0mthe\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minstead\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m)\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m         \"\"\"\n\u001B[1;32m--> 315\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    316\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfinish_update\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptimizer\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy_transformers\\layers\\transformer_model.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(model, docs, is_train)\u001B[0m\n\u001B[0;32m    175\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;34m\"logger\"\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    176\u001B[0m         \u001B[0mlog_gpu_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"logger\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"begin forward\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 177\u001B[1;33m     \u001B[0mbatch_encoding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhuggingface_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mspan\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mspan\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mflat_spans\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    178\u001B[0m     \u001B[0mwordpieces\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mWordpieceBatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_batch_encoding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_encoding\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;34m\"logger\"\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy_transformers\\layers\\transformer_model.py\u001B[0m in \u001B[0;36mhuggingface_tokenize\u001B[1;34m(tokenizer, texts)\u001B[0m\n\u001B[0;32m    269\u001B[0m     \u001B[1;31m# host <-> device transfers during tokenization and post-processing\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    270\u001B[0m     \u001B[1;31m# when a GPU is used.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 271\u001B[1;33m     token_data = tokenizer(\n\u001B[0m\u001B[0;32m    272\u001B[0m         \u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    273\u001B[0m         \u001B[0madd_special_tokens\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2416\u001B[0m                 )\n\u001B[0;32m   2417\u001B[0m             \u001B[0mbatch_text_or_text_pairs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext_pair\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mtext_pair\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2418\u001B[1;33m             return self.batch_encode_plus(\n\u001B[0m\u001B[0;32m   2419\u001B[0m                 \u001B[0mbatch_text_or_text_pairs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_text_or_text_pairs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2420\u001B[0m                 \u001B[0madd_special_tokens\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0madd_special_tokens\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001B[0m in \u001B[0;36mbatch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2607\u001B[0m         )\n\u001B[0;32m   2608\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2609\u001B[1;33m         return self._batch_encode_plus(\n\u001B[0m\u001B[0;32m   2610\u001B[0m             \u001B[0mbatch_text_or_text_pairs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_text_or_text_pairs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2611\u001B[0m             \u001B[0madd_special_tokens\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0madd_special_tokens\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\transformers\\models\\gpt2\\tokenization_gpt2_fast.py\u001B[0m in \u001B[0;36m_batch_encode_plus\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m         )\n\u001B[0;32m    163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 164\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_batch_encode_plus\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    166\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_encode_plus\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mBatchEncoding\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py\u001B[0m in \u001B[0;36m_batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001B[0m\n\u001B[0;32m    407\u001B[0m         )\n\u001B[0;32m    408\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 409\u001B[1;33m         encodings = self._tokenizer.encode_batch(\n\u001B[0m\u001B[0;32m    410\u001B[0m             \u001B[0mbatch_text_or_text_pairs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    411\u001B[0m             \u001B[0madd_special_tokens\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0madd_special_tokens\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "comment_dict = {}\n",
    "count = 0\n",
    "for doc in nlp.pipe(tqdm(df.clean_comments)):\n",
    "    doc_ents_id = []\n",
    "    comment_dict[f'{count}'] = {'comment': doc.text}\n",
    "    comment_dict[f'{count}']['entities'] = []\n",
    "    for ent in doc.ents:\n",
    "        relevant_sections = {}\n",
    "        if ent.kb_id_ != 'NIL':\n",
    "            ent_details = ent.kb_id_\n",
    "            doc_ents_id.append(ent_details)\n",
    "            comment.append(doc.text)\n",
    "            relevant_sections[f'{ent.kb_id_}'] = []\n",
    "            current_token = ent[0]\n",
    "            subject_count = 1\n",
    "            while current_token.dep_ != \"ROOT\" and subject_count <= 1:\n",
    "                if current_token.dep_ ==  'nsubj' or current_token.dep_== 'iobj' or current_token.dep_== 'dobj' or current_token.dep_ == 'pobj':\n",
    "                    subject_count += 1\n",
    "                    current_token = current_token.head\n",
    "                else:\n",
    "                    current_token = current_token.head\n",
    "                section = [t for t in current_token.subtree]\n",
    "            relevant_sections[f'{ent.kb_id_}'].append(section)\n",
    "    comment_dict[f'{count}']['entities'].append(relevant_sections)\n",
    "    count +=1\n",
    "    comment_ents.append(doc_ents)\n",
    "    comment.append(doc.text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "zip_data = zip(comment_ents, comment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "comment_df = pd.DataFrame(data = zip_data, columns = ['comment_entities', 'comment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comment_df.to_pickle('../data/comments_entities_only.pk1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comment_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comment_df = pd.DataFrame(data = zip_data, columns = ['entities', 'polarity', 'subjectivity'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comment_df['comment'] = [comment for comment in df.comment]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comment_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores = df.merge(right = comment_df, how = 'left', right_on = 'comment', left_on = 'comment')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title_df= pd.DataFrame({'title': title_list, 'title_ents': title_ents})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores.drop(columns = ['Unnamed: 0'] , inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores['date_time'] = [date for date in df_with_scores.date_time]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores = df_with_scores.merge(right = title_df, how = 'left', left_on = 'sub_title', right_on = 'title')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_scores['entities_both'] = np.where(df_with_scores.entities.map(lambda x: len(x)) ==0, df_with_scores.title_ents, df_with_scores.entities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean = df_with_scores.dropna(axis = 0, how = 'any', inplace = False)\n",
    "df_clean.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean['len_entities_both'] = [len(entity) for entity in df_clean.entities_both]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2 = df_clean[df_clean.len_entities_both >= 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comments = [comment for comment in df_clean2.comment]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "sentiment = pipeline(task = 'sentiment-analysis', model = 'cardiffnlp/twitter-roberta-base-sentiment', tokenizer = tokenizer, device = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "sents = sentiment(comments, max_length = 512, truncation = True, padding = 'max_length', batch_size = 64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['label_h'] = [sents['label'] for sents in sents]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['label_h'] = df_clean2['label_h'].map({'LABEL_0': -1, 'LABEL_1': 0, 'LABEL_2': 1})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['score_h'] = [sents['score'] for sents in sents]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['sent_score_h'] = df_clean2.score * df_clean2.label_h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['date'] = [dt.utcfromtimestamp(time) for time in df_clean2['date_time']]\n",
    "df_clean2['year_month'] = [date_time.to_period(\"M\") for date_time in df_clean2.date]\n",
    "df_clean2.year_month = [d_t.strftime('%Y-%m') for d_t in df_clean2.year_month]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.reset_index(inplace = True, drop = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.entities = [list(set(entity)) for entity in df_clean2.entities]\n",
    "df_clean2.entities_both = [list(set(entity)) for entity in df_clean2.entities_both]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['len_entities'] = [len(entity) for entity in df_clean2.entities_both]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2 = df_clean2[df_clean2.len_entities >= 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entities = []\n",
    "for ents in df_clean2.entities:\n",
    "    for ent in ents:\n",
    "        entities.append(ent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_entities = sorted(set(entities))\n",
    "unique_entities = [entity for entity in unique_entities]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(unique_entities, columns = ['entities']).to_csv('../data/entity_list.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_dates = [item for item in df_clean2.year_month.unique()]\n",
    "pd.DataFrame(sorted_dates, columns = ['month']).sort_values(by= 'month', ascending=True).to_csv('../data/date_list.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['label_t'] =np.where(df_clean2.polarity < -0.05, '-1',\n",
    "                            np.where(df_clean2.polarity >0.05, '1', '0'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['output_v'] = [analyzer.polarity_scores(comment) for comment in tqdm(df_clean2.comment)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['score_v'] = [output['compound'] for output in df_clean2.output_v]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2['label_v'] = np.where(df_clean2.polarity < -0.05, '-1',\n",
    "                               np.where(df_clean2.polarity >0.05, '1', '0'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.reset_index(inplace = True, drop = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for item in tqdm(unique_entities):\n",
    "    rows = []\n",
    "    for index,row in df_clean2.iterrows():\n",
    "        if item in row.entities:\n",
    "            rows.append(row.values)\n",
    "    item_df = pd.DataFrame(data = rows, columns = df_clean2.columns)\n",
    "    item_df.entities = item\n",
    "    item_df.to_pickle(f'../data/indiv_data/{item}.pk1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clean2.to_pickle('../data/label_data.pk1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}